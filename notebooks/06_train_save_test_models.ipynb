{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# تدريب وحفظ واختبار النماذج\n",
    "\n",
    "تدريب وحفظ واختبار جميع النماذج المستخدمة في المشروع"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## استيراد المكتبات المطلوبة"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cluster import KMeans\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "import joblib\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# تعيين مستوى التسجيل\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## تحميل وتحضير البيانات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "أبعاد البيانات: (3000, 12)\n"
     ]
    }
   ],
   "source": [
    "# تحميل البيانات المعالجة\n",
    "df = pd.read_csv('../data/processed/sales_data_processed_20250122_052318.csv')\n",
    "print('أبعاد البيانات:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تم تحضير الميزات بنجاح\n"
     ]
    }
   ],
   "source": [
    "# تحضير الميزات\n",
    "def prepare_features(df):\n",
    "    # تشفير المتغيرات الفئوية\n",
    "    le = LabelEncoder()\n",
    "    categorical_cols = ['Category', 'Region', 'Segment']\n",
    "    encoded_cols = {}\n",
    "    for col in categorical_cols:\n",
    "        df[f'{col}_Encoded'] = le.fit_transform(df[col])\n",
    "        encoded_cols[col] = le\n",
    "    \n",
    "    # تطبيع المتغيرات العددية\n",
    "    scaler = StandardScaler()\n",
    "    numeric_cols = ['Quantity', 'Sales', 'Discount', 'Profit']\n",
    "    scaled_cols = {}\n",
    "    for col in numeric_cols:\n",
    "        df[f'{col}_Scaled'] = scaler.fit_transform(df[[col]])\n",
    "        scaled_cols[col] = scaler\n",
    "    \n",
    "    return df, encoded_cols, scaled_cols\n",
    "\n",
    "# تحضير البيانات\n",
    "df, encoders, scalers = prepare_features(df)\n",
    "print('تم تحضير الميزات بنجاح')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## تدريب النماذج"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "دقة نموذج شجرة القرار: 0.32\n"
     ]
    }
   ],
   "source": [
    "# تدريب نموذج شجرة القرار\n",
    "def train_decision_tree(df):\n",
    "    features = ['Year', 'Month', 'Quarter', 'Quantity_Scaled', 'Discount_Scaled',\n",
    "                'Category_Encoded', 'Region_Encoded', 'Segment_Encoded']\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df['Sales_Category']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    dt = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy = dt.score(X_test, y_test)\n",
    "    print(f'دقة نموذج شجرة القرار: {accuracy:.2f}')\n",
    "    \n",
    "    return dt, (X_test, y_test)\n",
    "\n",
    "# تدريب النموذج\n",
    "dt_model, dt_test_data = train_decision_tree(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "دقة نموذج Naive Bayes: 0.30\n"
     ]
    }
   ],
   "source": [
    "# تدريب نموذج Naive Bayes\n",
    "def train_naive_bayes(df):\n",
    "    features = ['Year', 'Month', 'Quarter', 'Quantity_Scaled', 'Discount_Scaled',\n",
    "                'Category_Encoded', 'Region_Encoded', 'Segment_Encoded']\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df['Sales_Category']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    nb = GaussianNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy = nb.score(X_test, y_test)\n",
    "    print(f'دقة نموذج Naive Bayes: {accuracy:.2f}')\n",
    "    \n",
    "    return nb, (X_test, y_test)\n",
    "\n",
    "# تدريب النموذج\n",
    "nb_model, nb_test_data = train_naive_bayes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\data_mining_project\\.venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "d:\\python\\data_mining_project\\.venv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"d:\\python\\data_mining_project\\.venv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "متوسط مسافة النقاط عن مراكزها: 8278.80\n"
     ]
    }
   ],
   "source": [
    "# تدريب نموذج K-means\n",
    "def train_kmeans(df):\n",
    "    features = ['Quantity_Scaled', 'Sales_Scaled', 'Discount_Scaled', 'Profit_Scaled']\n",
    "    X = df[features]\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    \n",
    "    inertia = kmeans.inertia_\n",
    "    print(f'متوسط مسافة النقاط عن مراكزها: {inertia:.2f}')\n",
    "    \n",
    "    return kmeans, X\n",
    "\n",
    "# تدريب النموذج\n",
    "kmeans_model, kmeans_data = train_kmeans(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تم استخراج 111 قاعدة ارتباط\n"
     ]
    }
   ],
   "source": [
    "# تدريب نموذج Apriori\n",
    "def train_apriori(df):\n",
    "    # إنشاء جدول المعاملات\n",
    "    transactions = df.groupby(['Order_Date'])[['Category', 'Region', 'Segment']].agg(lambda x: list(x))\n",
    "    \n",
    "    # تحويل البيانات إلى تنسيق ثنائي\n",
    "    encoded_vals = []\n",
    "    for index, row in transactions.iterrows():\n",
    "        rowset = []\n",
    "        for item in row:\n",
    "            rowset.extend(item)\n",
    "        encoded_vals.append(rowset)\n",
    "    \n",
    "    # إنشاء DataFrame مشفر\n",
    "    ohe = pd.get_dummies(pd.DataFrame(encoded_vals))\n",
    "    \n",
    "    # إيجاد مجموعات العناصر المتكررة\n",
    "    frequent_itemsets = apriori(ohe, min_support=0.01, use_colnames=True)\n",
    "    \n",
    "    # استخراج قواعد الارتباط\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.3)\n",
    "    \n",
    "    print(f'تم استخراج {len(rules)} قاعدة ارتباط')\n",
    "    \n",
    "    return rules\n",
    "\n",
    "# تدريب النموذج\n",
    "apriori_rules = train_apriori(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## حفظ النماذج"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تم حفظ نموذج decision_tree في ../models/decision_tree_20250122_052900.joblib\n",
      "تم حفظ نموذج naive_bayes في ../models/naive_bayes_20250122_052900.joblib\n",
      "تم حفظ نموذج kmeans في ../models/kmeans_20250122_052900.joblib\n",
      "تم حفظ نموذج apriori في ../models/apriori_20250122_052900.joblib\n",
      "تم حفظ المشفرات في ../models/encoders_20250122_052900.joblib\n",
      "تم حفظ المطبعات في ../models/scalers_20250122_052900.joblib\n"
     ]
    }
   ],
   "source": [
    "def save_models(models, encoders, scalers):\n",
    "    # إنشاء مجلد للنماذج\n",
    "    os.makedirs('../models', exist_ok=True)\n",
    "    \n",
    "    # حفظ النماذج\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model_path = f'../models/{name}_{timestamp}.joblib'\n",
    "        joblib.dump(model, model_path)\n",
    "        print(f'تم حفظ نموذج {name} في {model_path}')\n",
    "    \n",
    "    # حفظ المشفرات\n",
    "    encoder_path = f'../models/encoders_{timestamp}.joblib'\n",
    "    joblib.dump(encoders, encoder_path)\n",
    "    print(f'تم حفظ المشفرات في {encoder_path}')\n",
    "    \n",
    "    # حفظ المطبعات\n",
    "    scaler_path = f'../models/scalers_{timestamp}.joblib'\n",
    "    joblib.dump(scalers, scaler_path)\n",
    "    print(f'تم حفظ المطبعات في {scaler_path}')\n",
    "\n",
    "# تجميع النماذج\n",
    "models = {\n",
    "    'decision_tree': dt_model,\n",
    "    'naive_bayes': nb_model,\n",
    "    'kmeans': kmeans_model,\n",
    "    'apriori': apriori_rules\n",
    "}\n",
    "\n",
    "# حفظ النماذج\n",
    "save_models(models, encoders, scalers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## اختبار النماذج"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تم حفظ نتائج الاختبار في ../results/model_test_results_20250122_052900.txt\n",
      "\n",
      "نتائج الاختبار:\n",
      "decision_tree: 0.3183\n",
      "naive_bayes: 0.2967\n",
      "kmeans: 8278.7980\n"
     ]
    }
   ],
   "source": [
    "def test_models(models, test_data):\n",
    "    results = {}\n",
    "    \n",
    "    # اختبار شجرة القرار\n",
    "    if 'decision_tree' in models and 'decision_tree' in test_data:\n",
    "        dt = models['decision_tree']\n",
    "        X_test, y_test = test_data['decision_tree']\n",
    "        dt_accuracy = dt.score(X_test, y_test)\n",
    "        results['decision_tree'] = dt_accuracy\n",
    "    \n",
    "    # اختبار Naive Bayes\n",
    "    if 'naive_bayes' in models and 'naive_bayes' in test_data:\n",
    "        nb = models['naive_bayes']\n",
    "        X_test, y_test = test_data['naive_bayes']\n",
    "        nb_accuracy = nb.score(X_test, y_test)\n",
    "        results['naive_bayes'] = nb_accuracy\n",
    "    \n",
    "    # اختبار K-means\n",
    "    if 'kmeans' in models and 'kmeans' in test_data:\n",
    "        kmeans = models['kmeans']\n",
    "        X = test_data['kmeans']\n",
    "        inertia = kmeans.inertia_\n",
    "        results['kmeans'] = inertia\n",
    "    \n",
    "    # حفظ نتائج الاختبار\n",
    "    os.makedirs('../results', exist_ok=True)\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    results_file = f'../results/model_test_results_{timestamp}.txt'\n",
    "    \n",
    "    with open(results_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"نتائج اختبار النماذج\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\\n\")\n",
    "        for model_name, score in results.items():\n",
    "            f.write(f\"{model_name}: {score:.4f}\\n\")\n",
    "    \n",
    "    print(f'تم حفظ نتائج الاختبار في {results_file}')\n",
    "    return results\n",
    "\n",
    "# تجميع بيانات الاختبار\n",
    "test_data = {\n",
    "    'decision_tree': dt_test_data,\n",
    "    'naive_bayes': nb_test_data,\n",
    "    'kmeans': kmeans_data\n",
    "}\n",
    "\n",
    "# اختبار النماذج\n",
    "results = test_models(models, test_data)\n",
    "\n",
    "# عرض النتائج\n",
    "print('\\nنتائج الاختبار:')\n",
    "for model_name, score in results.items():\n",
    "    print(f'{model_name}: {score:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
